{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "427cdab9-b474-4be9-9604-2a6ceff82437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Model Accuracy: 0.193292815281094\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.50      1.00      0.67         4\n",
      "         4.0       0.45      0.45      0.45        11\n",
      "         5.0       0.34      0.68      0.45        95\n",
      "         6.0       0.37      0.74      0.50        86\n",
      "         7.0       0.35      0.78      0.49       237\n",
      "         8.0       0.42      0.52      0.47       154\n",
      "         9.0       0.35      0.59      0.44       138\n",
      "        10.0       0.32      0.37      0.34       134\n",
      "        11.0       0.26      0.32      0.29       119\n",
      "        12.0       0.42      0.47      0.44       274\n",
      "        13.0       0.18      0.22      0.20       156\n",
      "        14.0       0.32      0.34      0.33       236\n",
      "        15.0       0.21      0.24      0.23       177\n",
      "        16.0       0.27      0.27      0.27       188\n",
      "        17.0       0.17      0.16      0.17       137\n",
      "        18.0       0.21      0.23      0.22       229\n",
      "        19.0       0.17      0.15      0.16       190\n",
      "        20.0       0.14      0.11      0.12       259\n",
      "        21.0       0.19      0.16      0.17       173\n",
      "        22.0       0.24      0.30      0.27       291\n",
      "        23.0       0.06      0.04      0.05       167\n",
      "        24.0       0.29      0.33      0.31       251\n",
      "        25.0       0.10      0.05      0.07       148\n",
      "        26.0       0.20      0.23      0.21       242\n",
      "        27.0       0.14      0.11      0.12       204\n",
      "        28.0       0.13      0.12      0.13       291\n",
      "        29.0       0.15      0.12      0.13       185\n",
      "        30.0       0.06      0.05      0.05       234\n",
      "        31.0       0.08      0.07      0.08       153\n",
      "        32.0       0.08      0.08      0.08       222\n",
      "        33.0       0.08      0.07      0.07       184\n",
      "        34.0       0.07      0.07      0.07       194\n",
      "        35.0       0.17      0.17      0.17       160\n",
      "        36.0       0.17      0.15      0.16       242\n",
      "        37.0       0.11      0.10      0.10       168\n",
      "        38.0       0.11      0.12      0.11       217\n",
      "        39.0       0.15      0.12      0.13       148\n",
      "        40.0       0.10      0.12      0.11       161\n",
      "        41.0       0.12      0.11      0.12       163\n",
      "        42.0       0.17      0.11      0.14       183\n",
      "        43.0       0.04      0.04      0.04       136\n",
      "        44.0       0.15      0.13      0.14       168\n",
      "        45.0       0.13      0.12      0.12       110\n",
      "        46.0       0.09      0.12      0.10       151\n",
      "        47.0       0.09      0.05      0.07       100\n",
      "        48.0       0.08      0.08      0.08       135\n",
      "        49.0       0.04      0.04      0.04        93\n",
      "        50.0       0.10      0.08      0.09       112\n",
      "        51.0       0.06      0.05      0.06        94\n",
      "        52.0       0.10      0.09      0.09        89\n",
      "        53.0       0.07      0.05      0.06        87\n",
      "        54.0       0.06      0.03      0.04        96\n",
      "        55.0       0.11      0.09      0.10        55\n",
      "        56.0       0.12      0.12      0.12        80\n",
      "        57.0       0.03      0.03      0.03        36\n",
      "        58.0       0.07      0.06      0.07        64\n",
      "        59.0       0.07      0.06      0.07        32\n",
      "        60.0       0.00      0.00      0.00        35\n",
      "        61.0       0.14      0.11      0.12        45\n",
      "        62.0       0.14      0.07      0.10        54\n",
      "        63.0       0.14      0.08      0.10        38\n",
      "        64.0       0.14      0.10      0.12        31\n",
      "        65.0       0.00      0.00      0.00        14\n",
      "        66.0       0.16      0.08      0.11        38\n",
      "        67.0       0.00      0.00      0.00        17\n",
      "        68.0       0.00      0.00      0.00        13\n",
      "        69.0       0.14      0.08      0.10        13\n",
      "        70.0       0.00      0.00      0.00        13\n",
      "        71.0       0.17      0.08      0.11        12\n",
      "        72.0       0.00      0.00      0.00        10\n",
      "        73.0       0.00      0.00      0.00         5\n",
      "        74.0       0.00      0.00      0.00        10\n",
      "        75.0       0.00      0.00      0.00         2\n",
      "        76.0       0.00      0.00      0.00         1\n",
      "        77.0       0.25      0.12      0.17         8\n",
      "        78.0       0.00      0.00      0.00         1\n",
      "        79.0       0.00      0.00      0.00         2\n",
      "        80.0       0.00      0.00      0.00         1\n",
      "        81.0       0.00      0.00      0.00         1\n",
      "        82.0       0.00      0.00      0.00         0\n",
      "        84.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.19      9214\n",
      "   macro avg       0.13      0.15      0.14      9214\n",
      "weighted avg       0.17      0.19      0.18      9214\n",
      "\n",
      "Shape of X_cat: (46068, 30)\n",
      "Shape of combined_features: (46068, 1100)\n",
      "Type of X_cat: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of combined_features: <class 'scipy.sparse._coo.coo_matrix'>\n",
      "Dtype of X_cat: cinsiyet                                                float64\n",
      "dogum_yeri                                               object\n",
      "ikametgah_sehri                                          object\n",
      "universite_adi                                           object\n",
      "universite_turu                                          object\n",
      "burs_aliyor_mu?                                           int64\n",
      "universite_kacinci_sinif                                 object\n",
      "universite_not_ortalamasi                               float64\n",
      "lise_mezuniyet_notu                                      object\n",
      "baska_bir_kurumdan_burs_aliyor_mu?                      float64\n",
      "baska_kurumdan_aldigi_burs_miktari                       object\n",
      "anne_calisma_durumu                                       int64\n",
      "baba_calisma_durumu                                       int64\n",
      "kardes_sayisi                                           float64\n",
      "girisimcilik_kulupleri_tarzi_bir_kulube_uye_misiniz?    float64\n",
      "profesyonel_bir_spor_daliyla_mesgul_musunuz?            float64\n",
      "aktif_olarak_bir_stk_uyesi_misiniz?                       int64\n",
      "girisimcilikle_ilgili_deneyiminiz_var_mi?                object\n",
      "ingilizce_biliyor_musunuz?                                int64\n",
      "anne_sektor_encoded                                       int64\n",
      "baba_sektor_encoded                                       int64\n",
      "anne_unknown                                               bool\n",
      "anne_diger                                                 bool\n",
      "anne_kamu                                                  bool\n",
      "anne_ozel_sektor                                           bool\n",
      "baba_unknown                                               bool\n",
      "baba_diger                                                 bool\n",
      "baba_kamu                                                  bool\n",
      "baba_ozel_sektor                                           bool\n",
      "age                                                       int64\n",
      "dtype: object\n",
      "Dtype of combined_features: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_cat_preprocessed: (46068, 1828)\n",
      "Shape of combined_features: (46068, 1100)\n",
      "Shape of X_combined: (46068, 2928)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 5873, in fit\n    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 2395, in _fit\n    train_params = self._prepare_train_params(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 2367, in _prepare_train_params\n    raise CatBoostError(\"To employ param {'use_best_model': True} provide non-empty 'eval_set'.\")\n_catboost.CatBoostError: To employ param {'use_best_model': True} provide non-empty 'eval_set'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 206\u001b[0m\n\u001b[0;32m    203\u001b[0m     catboost_model\u001b[38;5;241m.\u001b[39msave_model(catboost_model_path)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# Cross-validation\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m cross_val_score(catboost_model, X_combined, y, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCross-validation RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;241m-\u001b[39mcv_scores\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Predict and evaluate regression model\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    713\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    714\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    715\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    716\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    717\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    718\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    719\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    720\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    721\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    722\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    723\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    724\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    725\u001b[0m )\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[1;32m--> 443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 5873, in fit\n    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 2395, in _fit\n    train_params = self._prepare_train_params(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 2367, in _prepare_train_params\n    raise CatBoostError(\"To employ param {'use_best_model': True} provide non-empty 'eval_set'.\")\n_catboost.CatBoostError: To employ param {'use_best_model': True} provide non-empty 'eval_set'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostRegressor\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('cleanedData.csv')\n",
    "\n",
    "# Drop rows with missing target values\n",
    "df = df.drop(['burslu_ise_burs_yuzdesi', 'daha_once_baska_bir_universiteden_mezun_olmus', 'lise_adi_diger', 'lise_bolum_diger',\n",
    "              'uye_oldugunuz_kulubun_ismi', 'stk_projesine_katildiniz_mi?', 'ingilizce_seviyeniz?',\n",
    "              'daha_onceden_mezun_olunduysa_mezun_olunan_universite'], axis=1)\n",
    "df = df.dropna(subset=['degerlendirme_puani'])\n",
    "\n",
    "# Define relevant columns\n",
    "cat_features = [\n",
    "    'cinsiyet', 'dogum_yeri', 'ikametgah_sehri', 'universite_adi', 'universite_turu',\n",
    "    'burs_aliyor_mu?', 'universite_kacinci_sinif', 'universite_not_ortalamasi',\n",
    "    'lise_mezuniyet_notu', 'baska_bir_kurumdan_burs_aliyor_mu?', 'baska_kurumdan_aldigi_burs_miktari', \n",
    "    'anne_calisma_durumu', 'baba_calisma_durumu', 'kardes_sayisi',\n",
    "    'girisimcilik_kulupleri_tarzi_bir_kulube_uye_misiniz?', 'profesyonel_bir_spor_daliyla_mesgul_musunuz?',\n",
    "    'aktif_olarak_bir_stk_uyesi_misiniz?', 'girisimcilikle_ilgili_deneyiminiz_var_mi?', 'ingilizce_biliyor_musunuz?',\n",
    "    'anne_sektor_encoded', 'baba_sektor_encoded', 'anne_unknown', 'anne_diger', 'anne_kamu',\n",
    "    'anne_ozel_sektor', 'baba_unknown', 'baba_diger', 'baba_kamu', 'baba_ozel_sektor', 'age'\n",
    "]\n",
    "\n",
    "text_columns = ['girisimcilikle_ilgili_deneyiminizi_aciklayabilir_misiniz?', \"bolum\", \"lise_adi\", 'lise_sehir', 'lise_turu', 'lise_bolumu',\n",
    "                'burs_aldigi_baska_kurum', 'anne_egitim_durumu', 'baba_egitim_durumu', 'spor_dalindaki_rolunuz_nedir?', \"hangi_stk_nin_uyesisiniz?\"]\n",
    "target_column = 'degerlendirme_puani'\n",
    "\n",
    "# Handle missing values in text columns\n",
    "df[text_columns] = df[text_columns].fillna('')\n",
    "\n",
    "# Combine text columns into one for processing\n",
    "df['combined_text'] = df[text_columns].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Tokenize and preprocess text data for Word2Vec\n",
    "def preprocess_text(text):\n",
    "    return simple_preprocess(text, deacc=True)\n",
    "\n",
    "# Check if the Word2Vec model already exists\n",
    "if os.path.exists('word2vec_model.model'):\n",
    "    word2vec_model = Word2Vec.load('word2vec_model.model')\n",
    "else:\n",
    "    sentences = [preprocess_text(text) for text in df['combined_text']]\n",
    "    word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    word2vec_model.save('word2vec_model.model')\n",
    "\n",
    "# Create document vectors by averaging word vectors\n",
    "def vectorize_text(text):\n",
    "    tokens = preprocess_text(text)\n",
    "    vectors = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "df['text_vector'] = df['combined_text'].apply(vectorize_text)\n",
    "word2vec_features = np.array(df['text_vector'].tolist())\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "text_data = df['combined_text']\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(text_data)\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "# Combine Word2Vec and TF-IDF features\n",
    "combined_features = hstack([tfidf_vectors, word2vec_features])\n",
    "\n",
    "# Debugging step: Verify columns in df and missing columns in cat_features\n",
    "missing_cols = [col for col in cat_features if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(\"Warning: The following columns are missing from the DataFrame:\", missing_cols)\n",
    "\n",
    "# Prepare data for classification model\n",
    "try:\n",
    "    X_cat = df[cat_features]\n",
    "except KeyError as e:\n",
    "    print(\"Error: One or more columns are missing:\", e)\n",
    "    print(\"Available columns:\", df.columns)\n",
    "    raise\n",
    "\n",
    "y = df[target_column]\n",
    "\n",
    "# ColumnTransformer for encoding categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on the data\n",
    "X_cat_preprocessed = preprocessor.fit_transform(X_cat)\n",
    "\n",
    "# Save the fitted preprocessor\n",
    "joblib.dump(preprocessor, 'preprocessor.joblib')\n",
    "\n",
    "# Classification pipeline\n",
    "clf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Split data for classification model\n",
    "X_cat_train, X_cat_test, y_train, y_test = train_test_split(X_cat, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classification model\n",
    "clf_pipeline.fit(X_cat_train, y_train)\n",
    "\n",
    "# Evaluate classification model\n",
    "y_pred_cat = clf_pipeline.predict(X_cat_test)\n",
    "print(\"Classification Model Accuracy:\", accuracy_score(y_test, y_pred_cat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_cat))\n",
    "\n",
    "# Prepare data for regression model\n",
    "# Debugging step: Print shapes and types\n",
    "print(\"Shape of X_cat:\", X_cat.shape)\n",
    "print(\"Shape of combined_features:\", combined_features.shape)\n",
    "print(\"Type of X_cat:\", type(X_cat))\n",
    "print(\"Type of combined_features:\", type(combined_features))\n",
    "print(\"Dtype of X_cat:\", X_cat.dtypes)\n",
    "print(\"Dtype of combined_features:\", combined_features.dtype)\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X_cat.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_cat.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Create preprocessor for numeric and categorical features\n",
    "preprocessor_reg = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "X_cat_preprocessed = preprocessor_reg.fit_transform(X_cat)\n",
    "\n",
    "# Debugging step: Print shapes after preprocessing\n",
    "print(\"Shape of X_cat_preprocessed:\", X_cat_preprocessed.shape)\n",
    "print(\"Shape of combined_features:\", combined_features.shape)\n",
    "\n",
    "# Combine features\n",
    "X_combined = hstack([X_cat_preprocessed, combined_features])\n",
    "\n",
    "# Debugging step: Print final combined shape\n",
    "print(\"Shape of X_combined:\", X_combined.shape)\n",
    "\n",
    "# Split data for regression model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Load or train CatBoost model\n",
    "catboost_model_path = 'catboost_model.cbm'\n",
    "if os.path.exists(catboost_model_path):\n",
    "    catboost_model = CatBoostRegressor()\n",
    "    catboost_model.load_model(catboost_model_path)\n",
    "else:\n",
    "    # Modify CatBoost hyperparameters\n",
    "    catboost_model = CatBoostRegressor(\n",
    "        iterations=2000,  # Increased iterations\n",
    "        learning_rate=0.01,  # Lowered learning rate\n",
    "        depth=8,  # Increased depth\n",
    "        l2_leaf_reg=3,  # Added L2 regularization\n",
    "        loss_function='RMSE',\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        verbose=100,\n",
    "        early_stopping_rounds=500  # Increased early stopping rounds\n",
    "    )\n",
    "\n",
    "    # Add feature selection\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "    selector = SelectFromModel(estimator=CatBoostRegressor(iterations=100), threshold='median')\n",
    "    X_selected = selector.fit_transform(X_combined, y)\n",
    "\n",
    "    # Split data using selected features\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Train the model with selected features\n",
    "    catboost_model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=(X_test, y_test),\n",
    "        use_best_model=True,\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    # Save the CatBoost model\n",
    "    catboost_model.save_model(catboost_model_path)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(catboost_model, X_combined, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f'Cross-validation RMSE: {(-cv_scores.mean())**0.5:.4f} (+/- {cv_scores.std() * 2:.4f})')\n",
    "\n",
    "# Predict and evaluate regression model\n",
    "y_pred_reg = catboost_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_reg)\n",
    "rmse = mse ** 0.5\n",
    "print(f'Regression Model RMSE: {rmse:.4f}')\n",
    "\n",
    "# Print actual vs predicted values for regression\n",
    "print(\"\\nSample Actual vs. Predicted Values:\")\n",
    "for actual, predicted in zip(y_test[:10], y_pred_reg[:10]):\n",
    "    print(f\"Actual: {actual:.2f}, Predicted: {predicted:.2f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = catboost_model.feature_importances_\n",
    "feature_names = preprocessor_reg.get_feature_names_out().tolist() + [f'text_feature_{i}' for i in range(combined_features.shape[1])]\n",
    "for name, importance in sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(f\"Feature: {name}, Importance: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73b7229d-b3a6-4ecb-ad76-1b82c968a425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessor.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    return simple_preprocess(text, deacc=True)\n",
    "\n",
    "# Check if the Word2Vec model already exists\n",
    "\n",
    "# Create document vectors by averaging word vectors\n",
    "def vectorize_text(text):\n",
    "    tokens = preprocess_text(text)\n",
    "    vectors = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "df['text_vector'] = df['combined_text'].apply(vectorize_text)\n",
    "word2vec_features = np.array(df['text_vector'].tolist())\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "text_data = df['combined_text']\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(text_data)\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "# Combine Word2Vec and TF-IDF features\n",
    "combined_features = hstack([tfidf_vectors, word2vec_features])\n",
    "\n",
    "# Debugging step: Verify columns in df and missing columns in cat_features\n",
    "missing_cols = [col for col in cat_features if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(\"Warning: The following columns are missing from the DataFrame:\", missing_cols)\n",
    "\n",
    "# Prepare data for classification model\n",
    "try:\n",
    "    X_cat = df[cat_features]\n",
    "except KeyError as e:\n",
    "    print(\"Error: One or more columns are missing:\", e)\n",
    "    print(\"Available columns:\", df.columns)\n",
    "    raise\n",
    "\n",
    "y = df[target_column]\n",
    "\n",
    "# ColumnTransformer for encoding categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Save the preprocessor\n",
    "joblib.dump(preprocessor, 'preprocessor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f63b1a4d-5df7-4f95-a140-b0c96c72218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11049\n",
      "0        amasya amasya munzur universitesi devlet sosya...\n",
      "1        konya konya hacettepe universitesi devlet ulus...\n",
      "2        istanbul istanbul kapadokya universitesi ozel ...\n",
      "3        mardin mardin mardin artuklu universitesi devl...\n",
      "4        samsun istanbul bogazici universitesi devlet i...\n",
      "                               ...                        \n",
      "11044    yozgat ankara gazi universitesi devlet endustr...\n",
      "11045    konya konya nigde omer halisdemir universitesi...\n",
      "11046    ankara ankara karabuk universitesi devlet elek...\n",
      "11047    adiyaman istanbul bursa uludag universitesi de...\n",
      "11048    nigde ankara hacettepe universitesi devlet end...\n",
      "Name: combined_text, Length: 11049, dtype: object\n",
      "column = Unnamed: 0:<class 'str'>\n",
      "column = basvuru_yili:<class 'str'>\n",
      "column = cinsiyet:<class 'str'>\n",
      "column = dogum_yeri:<class 'str'>\n",
      "column = ikametgah_sehri:<class 'str'>\n",
      "column = universite_adi:<class 'str'>\n",
      "column = universite_turu:<class 'str'>\n",
      "column = burslu_ise_burs_yuzdesi:<class 'str'>\n",
      "column = burs_aliyor_mu?:<class 'str'>\n",
      "column = bolum:<class 'str'>\n",
      "column = universite_kacinci_sinif:<class 'str'>\n",
      "column = universite_not_ortalamasi:<class 'str'>\n",
      "column = daha_once_baska_bir_universiteden_mezun_olmus:<class 'str'>\n",
      "column = lise_adi:<class 'str'>\n",
      "column = lise_adi_diger:<class 'str'>\n",
      "column = lise_sehir:<class 'str'>\n",
      "column = lise_turu:<class 'str'>\n",
      "column = lise_bolumu:<class 'str'>\n",
      "column = lise_bolum_diger:<class 'str'>\n",
      "column = lise_mezuniyet_notu:<class 'str'>\n",
      "column = baska_bir_kurumdan_burs_aliyor_mu?:<class 'str'>\n",
      "column = burs_aldigi_baska_kurum:<class 'str'>\n",
      "column = baska_kurumdan_aldigi_burs_miktari:<class 'str'>\n",
      "column = anne_egitim_durumu:<class 'str'>\n",
      "column = anne_calisma_durumu:<class 'str'>\n",
      "column = baba_egitim_durumu:<class 'str'>\n",
      "column = baba_calisma_durumu:<class 'str'>\n",
      "column = kardes_sayisi:<class 'str'>\n",
      "column = girisimcilik_kulupleri_tarzi_bir_kulube_uye_misiniz?:<class 'str'>\n",
      "column = uye_oldugunuz_kulubun_ismi:<class 'str'>\n",
      "column = profesyonel_bir_spor_daliyla_mesgul_musunuz?:<class 'str'>\n",
      "column = spor_dalindaki_rolunuz_nedir?:<class 'str'>\n",
      "column = aktif_olarak_bir_stk_uyesi_misiniz?:<class 'str'>\n",
      "column = hangi_stk_nin_uyesisiniz?:<class 'str'>\n",
      "column = stk_projesine_katildiniz_mi?:<class 'str'>\n",
      "column = girisimcilikle_ilgili_deneyiminiz_var_mi?:<class 'str'>\n",
      "column = girisimcilikle_ilgili_deneyiminizi_aciklayabilir_misiniz?:<class 'str'>\n",
      "column = ingilizce_biliyor_musunuz?:<class 'str'>\n",
      "column = ingilizce_seviyeniz?:<class 'str'>\n",
      "column = daha_onceden_mezun_olunduysa_mezun_olunan_universite:<class 'str'>\n",
      "column = id:<class 'str'>\n",
      "column = anne_sektor_encoded:<class 'str'>\n",
      "column = baba_sektor_encoded:<class 'str'>\n",
      "column = anne_unknown:<class 'str'>\n",
      "column = anne_diger:<class 'str'>\n",
      "column = anne_kamu:<class 'str'>\n",
      "column = anne_ozel_sektor:<class 'str'>\n",
      "column = baba_unknown:<class 'str'>\n",
      "column = baba_diger:<class 'str'>\n",
      "column = baba_kamu:<class 'str'>\n",
      "column = baba_ozel_sektor:<class 'str'>\n",
      "column = age:<class 'str'>\n",
      "column = combined_text:<class 'str'>\n",
      "column = text_vector:<class 'str'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Preprocess test data\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m X_test_cat_preprocessed \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(X_test_cat)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Combine features for test data\u001b[39;00m\n\u001b[0;32m     37\u001b[0m X_test_combined \u001b[38;5;241m=\u001b[39m hstack([X_test_cat_preprocessed, test_combined_features])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1076\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[1;32m-> 1076\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_func_on_transformers(\n\u001b[0;32m   1077\u001b[0m     X,\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1079\u001b[0m     _transform_one,\n\u001b[0;32m   1080\u001b[0m     column_as_labels\u001b[38;5;241m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[0;32m   1081\u001b[0m     routed_params\u001b[38;5;241m=\u001b[39mrouted_params,\n\u001b[0;32m   1082\u001b[0m )\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:885\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[1;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    875\u001b[0m             delayed(func)(\n\u001b[0;32m    876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    882\u001b[0m             )\n\u001b[0;32m    883\u001b[0m         )\n\u001b[1;32m--> 885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(jobs)\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:1290\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, params)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call transform and apply weight to output.\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;124;03m        This should be of the form ``process_routing()[\"step_name\"]``.\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1290\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mtransform)\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1024\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1023\u001b[0m }\n\u001b[1;32m-> 1024\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(\n\u001b[0;32m   1025\u001b[0m     X,\n\u001b[0;32m   1026\u001b[0m     handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown,\n\u001b[0;32m   1027\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1028\u001b[0m     warn_on_unknown\u001b[38;5;241m=\u001b[39mwarn_on_unknown,\n\u001b[0;32m   1029\u001b[0m )\n\u001b[0;32m   1031\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:206\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_features):\n\u001b[0;32m    205\u001b[0m     Xi \u001b[38;5;241m=\u001b[39m X_list[i]\n\u001b[1;32m--> 206\u001b[0m     diff, valid_mask \u001b[38;5;241m=\u001b[39m _check_unknown(Xi, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories_[i], return_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(valid_mask):\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:304\u001b[0m, in \u001b[0;36m_check_unknown\u001b[1;34m(values, known_values, return_mask)\u001b[0m\n\u001b[0;32m    301\u001b[0m         valid_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(values), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# check for nans in the known_values\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(known_values)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    305\u001b[0m     diff_is_nan \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(diff)\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff_is_nan\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;66;03m# removes nan from valid_mask\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('cleanTest.csv')\n",
    "test_df[\"cinsiyet\"] = test_df[\"cinsiyet\"].fillna(1.0)\n",
    "test_df = test_df.dropna(axis=0)\n",
    "\n",
    "df[text_columns] = df[text_columns].fillna('')\n",
    "\n",
    "\n",
    "print(len(test_df))\n",
    "# Preprocess test data\n",
    "test_df['combined_text'] = test_df[text_columns].apply(lambda x: ' '.join(x), axis=1)\n",
    "print(test_df[\"combined_text\"])\n",
    "\n",
    "\n",
    "# Create document vectors for test data\n",
    "test_df['text_vector'] = test_df['combined_text'].apply(vectorize_text)\n",
    "test_word2vec_features = np.array(test_df['text_vector'].tolist())\n",
    "\n",
    "# TF-IDF Vectorization for test data\n",
    "test_tfidf_vectors = tfidf_vectorizer.transform(test_df['combined_text'])\n",
    "\n",
    "# Combine Word2Vec and TF-IDF features for test data\n",
    "test_combined_features = hstack([test_tfidf_vectors, test_word2vec_features])\n",
    "\n",
    "# Prepare test data for the model\n",
    "X_test_cat = test_df[cat_features]\n",
    "\n",
    "\n",
    "# Preprocess test data\n",
    "X_test_cat_preprocessed = preprocessor.transform(X_test_cat)\n",
    "\n",
    "# Combine features for test data\n",
    "X_test_combined = hstack([X_test_cat_preprocessed, test_combined_features])\n",
    "\n",
    "# Apply feature selection\n",
    "X_test_selected = selector.transform(X_test_combined)\n",
    "\n",
    "# Load the saved CatBoost model\n",
    "loaded_model = CatBoostRegressor()\n",
    "loaded_model.load_model('catboost_model.cbm')\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = loaded_model.predict(X_test_selected)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Degerlendirme Puani': test_predictions\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submissionenson.csv', index=False)\n",
    "\n",
    "print(\"Predictions have been saved to 'submission.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51ff4f1a-4090-4a28-8a83-8d72038276e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mustafa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Example actual and predicted values\n",
    "y_true = np.array(puanlar)  # Real values\n",
    "y_pred = np.array(test_predictions)  # Predicted values\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "print(f'RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62161642-8d3d-43ad-8397-6b235b90a8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessor.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "joblib.dump(preprocessor, 'preprocessor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88097c3-e5e2-4bcb-a97c-a1e602d34fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
